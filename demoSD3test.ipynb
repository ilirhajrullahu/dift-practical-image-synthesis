{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\ludenbold\\anaconda3\\envs\\prakdift\\lib\\site-packages (2.5.1+cu124)\n",
      "Requirement already satisfied: diffusers in c:\\users\\ludenbold\\anaconda3\\envs\\prakdift\\lib\\site-packages (0.13.0)\n",
      "Requirement already satisfied: transformers in c:\\users\\ludenbold\\anaconda3\\envs\\prakdift\\lib\\site-packages (4.46.2)\n",
      "Requirement already satisfied: safetensors in c:\\users\\ludenbold\\anaconda3\\envs\\prakdift\\lib\\site-packages (0.4.5)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\ludenbold\\anaconda3\\envs\\prakdift\\lib\\site-packages (3.9.2)\n",
      "Requirement already satisfied: pillow in c:\\users\\ludenbold\\anaconda3\\envs\\prakdift\\lib\\site-packages (10.4.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\ludenbold\\anaconda3\\envs\\prakdift\\lib\\site-packages (from torch) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\ludenbold\\anaconda3\\envs\\prakdift\\lib\\site-packages (from torch) (4.11.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\ludenbold\\anaconda3\\envs\\prakdift\\lib\\site-packages (from torch) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\ludenbold\\anaconda3\\envs\\prakdift\\lib\\site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\ludenbold\\anaconda3\\envs\\prakdift\\lib\\site-packages (from torch) (2024.10.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\ludenbold\\anaconda3\\envs\\prakdift\\lib\\site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\ludenbold\\anaconda3\\envs\\prakdift\\lib\\site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: importlib-metadata in c:\\users\\ludenbold\\anaconda3\\envs\\prakdift\\lib\\site-packages (from diffusers) (8.5.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.10.0 in c:\\users\\ludenbold\\anaconda3\\envs\\prakdift\\lib\\site-packages (from diffusers) (0.25.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\ludenbold\\anaconda3\\envs\\prakdift\\lib\\site-packages (from diffusers) (1.26.4)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\ludenbold\\anaconda3\\envs\\prakdift\\lib\\site-packages (from diffusers) (2024.11.6)\n",
      "Requirement already satisfied: requests in c:\\users\\ludenbold\\anaconda3\\envs\\prakdift\\lib\\site-packages (from diffusers) (2.32.3)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\ludenbold\\anaconda3\\envs\\prakdift\\lib\\site-packages (from transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\ludenbold\\anaconda3\\envs\\prakdift\\lib\\site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in c:\\users\\ludenbold\\anaconda3\\envs\\prakdift\\lib\\site-packages (from transformers) (0.20.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\ludenbold\\anaconda3\\envs\\prakdift\\lib\\site-packages (from transformers) (4.67.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\ludenbold\\anaconda3\\envs\\prakdift\\lib\\site-packages (from matplotlib) (1.3.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\ludenbold\\anaconda3\\envs\\prakdift\\lib\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\ludenbold\\anaconda3\\envs\\prakdift\\lib\\site-packages (from matplotlib) (4.54.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\ludenbold\\anaconda3\\envs\\prakdift\\lib\\site-packages (from matplotlib) (1.4.7)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\ludenbold\\anaconda3\\envs\\prakdift\\lib\\site-packages (from matplotlib) (3.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\ludenbold\\anaconda3\\envs\\prakdift\\lib\\site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\ludenbold\\anaconda3\\envs\\prakdift\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\ludenbold\\anaconda3\\envs\\prakdift\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: zipp>=3.20 in c:\\users\\ludenbold\\anaconda3\\envs\\prakdift\\lib\\site-packages (from importlib-metadata->diffusers) (3.20.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\ludenbold\\anaconda3\\envs\\prakdift\\lib\\site-packages (from jinja2->torch) (3.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\ludenbold\\anaconda3\\envs\\prakdift\\lib\\site-packages (from requests->diffusers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\ludenbold\\anaconda3\\envs\\prakdift\\lib\\site-packages (from requests->diffusers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\ludenbold\\anaconda3\\envs\\prakdift\\lib\\site-packages (from requests->diffusers) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\ludenbold\\anaconda3\\envs\\prakdift\\lib\\site-packages (from requests->diffusers) (2024.8.30)\n",
      "Requirement already satisfied: diffusers==0.13.0 in c:\\users\\ludenbold\\anaconda3\\envs\\prakdift\\lib\\site-packages (0.13.0)\n",
      "Requirement already satisfied: importlib-metadata in c:\\users\\ludenbold\\anaconda3\\envs\\prakdift\\lib\\site-packages (from diffusers==0.13.0) (8.5.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\ludenbold\\anaconda3\\envs\\prakdift\\lib\\site-packages (from diffusers==0.13.0) (3.16.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.10.0 in c:\\users\\ludenbold\\anaconda3\\envs\\prakdift\\lib\\site-packages (from diffusers==0.13.0) (0.25.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\ludenbold\\anaconda3\\envs\\prakdift\\lib\\site-packages (from diffusers==0.13.0) (1.26.4)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\ludenbold\\anaconda3\\envs\\prakdift\\lib\\site-packages (from diffusers==0.13.0) (2024.11.6)\n",
      "Requirement already satisfied: requests in c:\\users\\ludenbold\\anaconda3\\envs\\prakdift\\lib\\site-packages (from diffusers==0.13.0) (2.32.3)\n",
      "Requirement already satisfied: Pillow in c:\\users\\ludenbold\\anaconda3\\envs\\prakdift\\lib\\site-packages (from diffusers==0.13.0) (10.4.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\ludenbold\\anaconda3\\envs\\prakdift\\lib\\site-packages (from huggingface-hub>=0.10.0->diffusers==0.13.0) (2024.10.0)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\users\\ludenbold\\anaconda3\\envs\\prakdift\\lib\\site-packages (from huggingface-hub>=0.10.0->diffusers==0.13.0) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\ludenbold\\anaconda3\\envs\\prakdift\\lib\\site-packages (from huggingface-hub>=0.10.0->diffusers==0.13.0) (6.0.2)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in c:\\users\\ludenbold\\anaconda3\\envs\\prakdift\\lib\\site-packages (from huggingface-hub>=0.10.0->diffusers==0.13.0) (4.67.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\ludenbold\\anaconda3\\envs\\prakdift\\lib\\site-packages (from huggingface-hub>=0.10.0->diffusers==0.13.0) (4.11.0)\n",
      "Requirement already satisfied: zipp>=3.20 in c:\\users\\ludenbold\\anaconda3\\envs\\prakdift\\lib\\site-packages (from importlib-metadata->diffusers==0.13.0) (3.20.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\ludenbold\\anaconda3\\envs\\prakdift\\lib\\site-packages (from requests->diffusers==0.13.0) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\ludenbold\\anaconda3\\envs\\prakdift\\lib\\site-packages (from requests->diffusers==0.13.0) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\ludenbold\\anaconda3\\envs\\prakdift\\lib\\site-packages (from requests->diffusers==0.13.0) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\ludenbold\\anaconda3\\envs\\prakdift\\lib\\site-packages (from requests->diffusers==0.13.0) (2024.8.30)\n",
      "Requirement already satisfied: colorama in c:\\users\\ludenbold\\anaconda3\\envs\\prakdift\\lib\\site-packages (from tqdm>=4.42.1->huggingface-hub>=0.10.0->diffusers==0.13.0) (0.4.6)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Ludenbold\\anaconda3\\envs\\PrakDiFT\\lib\\site-packages\\torchvision\\io\\image.py:13: UserWarning: Failed to load image Python extension: [WinError 127] Die angegebene Prozedur wurde nicht gefunden\n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n"
     ]
    }
   ],
   "source": [
    "%matplotlib widget\n",
    "# Demo for DIFT with Stable Diffusion 3\n",
    "\n",
    "# Ensure required libraries are installed\n",
    "!pip install torch diffusers transformers safetensors matplotlib pillow\n",
    "!pip install diffusers==0.13.0\n",
    "\n",
    "# Import Libraries and Initialize Featurizer\n",
    "from src.models.dift_sd import SDFeaturizer\n",
    "from torchvision.transforms import PILToTensor\n",
    "from PIL import Image\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3049d1fb97ab43528e457c5544b3af8c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Login to Hugging Face to access the model\n",
    "#from huggingface_hub import login\n",
    "#login()\n",
    "\n",
    "#not necessary now because of local model file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.path.exists(\"./sd3_medium.safetensors\"))  # Should return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Ludenbold\\anaconda3\\envs\\PrakDiFT\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 64.00 MiB. GPU 0 has a total capacity of 12.00 GiB of which 0 bytes is free. Of the allocated memory 22.51 GiB is allocated by PyTorch, and 128.00 KiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 7\u001b[0m\n\u001b[0;32m      5\u001b[0m current_dir \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mdirname(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mabspath(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./dift_sd.py\u001b[39m\u001b[38;5;124m\"\u001b[39m))  \u001b[38;5;66;03m# Get the current directory of dift_sd.py\u001b[39;00m\n\u001b[0;32m      6\u001b[0m model_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(current_dir, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msd3_medium.safetensors\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 7\u001b[0m featurizer \u001b[38;5;241m=\u001b[39m \u001b[43mSDFeaturizer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_path\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Ludenbold\\Desktop\\Master V\\Image&Video Synthesis Prak\\dift-practical-image-synthesis\\src\\models\\dift_sd.py:39\u001b[0m, in \u001b[0;36mSDFeaturizer.__init__\u001b[1;34m(self, model_path, null_prompt)\u001b[0m\n\u001b[0;32m     33\u001b[0m state_dict \u001b[38;5;241m=\u001b[39m load_file(model_path)\n\u001b[0;32m     35\u001b[0m \u001b[38;5;66;03m# Initialize MM-DiT (U-Net equivalent)\u001b[39;00m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;66;03m#self.mm_dit = self._initialize_mm_dit(state_dict)\u001b[39;00m\n\u001b[0;32m     37\u001b[0m \n\u001b[0;32m     38\u001b[0m \u001b[38;5;66;03m#Use .half() for memory efficiency (mixed precision)\u001b[39;00m\n\u001b[1;32m---> 39\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmm_dit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_initialize_mm_dit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate_dict\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mhalf()\n\u001b[0;32m     41\u001b[0m \u001b[38;5;66;03m# Load VAE for latent encoding\u001b[39;00m\n\u001b[0;32m     42\u001b[0m \u001b[38;5;66;03m# Replace the VAE loading in the initializer\u001b[39;00m\n\u001b[0;32m     43\u001b[0m \u001b[38;5;66;03m#self.vae = AutoencoderKL.from_pretrained(\"stabilityai/stable-diffusion-2-1\", subfolder=\"vae\").to(\"cuda\")\u001b[39;00m\n\u001b[0;32m     44\u001b[0m \n\u001b[0;32m     45\u001b[0m \u001b[38;5;66;03m#Use .half() for memory efficiency\u001b[39;00m\n\u001b[0;32m     46\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvae \u001b[38;5;241m=\u001b[39m AutoencoderKL\u001b[38;5;241m.\u001b[39mfrom_pretrained(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstabilityai/stable-diffusion-2-1\u001b[39m\u001b[38;5;124m\"\u001b[39m, subfolder\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvae\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mhalf()\n",
      "File \u001b[1;32mc:\\Users\\Ludenbold\\Desktop\\Master V\\Image&Video Synthesis Prak\\dift-practical-image-synthesis\\src\\models\\dift_sd.py:72\u001b[0m, in \u001b[0;36mSDFeaturizer._initialize_mm_dit\u001b[1;34m(self, state_dict)\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_initialize_mm_dit\u001b[39m(\u001b[38;5;28mself\u001b[39m, state_dict):\n\u001b[0;32m     63\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;124;03m    Initialize the MM-DiT (transformer-based model) from the provided state_dict.\u001b[39;00m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m     66\u001b[0m     mm_dit \u001b[38;5;241m=\u001b[39m \u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTransformer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     67\u001b[0m \u001b[43m        \u001b[49m\u001b[43md_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m4096\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Adjust to match latent and embedding dimensions\u001b[39;49;00m\n\u001b[0;32m     68\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnhead\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m16\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     69\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_encoder_layers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m24\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     70\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_decoder_layers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m24\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     71\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdim_feedforward\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m8192\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m---> 72\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcuda\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mhalf()\n\u001b[0;32m     74\u001b[0m     \u001b[38;5;66;03m# Clear unused memory\u001b[39;00m\n\u001b[0;32m     75\u001b[0m     torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mempty_cache()\n",
      "File \u001b[1;32mc:\\Users\\Ludenbold\\anaconda3\\envs\\PrakDiFT\\lib\\site-packages\\torch\\nn\\modules\\module.py:1340\u001b[0m, in \u001b[0;36mModule.to\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1337\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1338\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[1;32m-> 1340\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Ludenbold\\anaconda3\\envs\\PrakDiFT\\lib\\site-packages\\torch\\nn\\modules\\module.py:900\u001b[0m, in \u001b[0;36mModule._apply\u001b[1;34m(self, fn, recurse)\u001b[0m\n\u001b[0;32m    898\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[0;32m    899\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[1;32m--> 900\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    902\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[0;32m    903\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[0;32m    904\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[0;32m    905\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    910\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[0;32m    911\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Ludenbold\\anaconda3\\envs\\PrakDiFT\\lib\\site-packages\\torch\\nn\\modules\\module.py:900\u001b[0m, in \u001b[0;36mModule._apply\u001b[1;34m(self, fn, recurse)\u001b[0m\n\u001b[0;32m    898\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[0;32m    899\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[1;32m--> 900\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    902\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[0;32m    903\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[0;32m    904\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[0;32m    905\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    910\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[0;32m    911\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "    \u001b[1;31m[... skipping similar frames: Module._apply at line 900 (2 times)]\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\Ludenbold\\anaconda3\\envs\\PrakDiFT\\lib\\site-packages\\torch\\nn\\modules\\module.py:900\u001b[0m, in \u001b[0;36mModule._apply\u001b[1;34m(self, fn, recurse)\u001b[0m\n\u001b[0;32m    898\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[0;32m    899\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[1;32m--> 900\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    902\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[0;32m    903\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[0;32m    904\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[0;32m    905\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    910\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[0;32m    911\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Ludenbold\\anaconda3\\envs\\PrakDiFT\\lib\\site-packages\\torch\\nn\\modules\\module.py:927\u001b[0m, in \u001b[0;36mModule._apply\u001b[1;34m(self, fn, recurse)\u001b[0m\n\u001b[0;32m    923\u001b[0m \u001b[38;5;66;03m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[0;32m    924\u001b[0m \u001b[38;5;66;03m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[0;32m    925\u001b[0m \u001b[38;5;66;03m# `with torch.no_grad():`\u001b[39;00m\n\u001b[0;32m    926\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m--> 927\u001b[0m     param_applied \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparam\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    928\u001b[0m p_should_use_set_data \u001b[38;5;241m=\u001b[39m compute_should_use_set_data(param, param_applied)\n\u001b[0;32m    930\u001b[0m \u001b[38;5;66;03m# subclasses may have multiple child tensors so we need to use swap_tensors\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Ludenbold\\anaconda3\\envs\\PrakDiFT\\lib\\site-packages\\torch\\nn\\modules\\module.py:1326\u001b[0m, in \u001b[0;36mModule.to.<locals>.convert\u001b[1;34m(t)\u001b[0m\n\u001b[0;32m   1319\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m convert_to_format \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m t\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m5\u001b[39m):\n\u001b[0;32m   1320\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(\n\u001b[0;32m   1321\u001b[0m             device,\n\u001b[0;32m   1322\u001b[0m             dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1323\u001b[0m             non_blocking,\n\u001b[0;32m   1324\u001b[0m             memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format,\n\u001b[0;32m   1325\u001b[0m         )\n\u001b[1;32m-> 1326\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1327\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1328\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_floating_point\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_complex\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1329\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1330\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1331\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m   1332\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(e) \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot copy out of meta tensor; no data!\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "\u001b[1;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 64.00 MiB. GPU 0 has a total capacity of 12.00 GiB of which 0 bytes is free. Of the allocated memory 22.51 GiB is allocated by PyTorch, and 128.00 KiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "source": [
    "# Initialize the SDFeaturizer for Stable Diffusion 3\n",
    "# Assuming 'sd3_medium.safetensors' is in the same directory as 'demoSD3test.ipynb'\n",
    "import os\n",
    "\n",
    "current_dir = os.path.dirname(os.path.abspath(\"./dift_sd.py\"))  # Get the current directory of dift_sd.py\n",
    "model_path = os.path.join(current_dir, \"sd3_medium.safetensors\")\n",
    "featurizer = SDFeaturizer(model_path=model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and Process a Sample Image\n",
    "img_path = \"./assets/cat.png\"  # Replace with your image path\n",
    "img = Image.open(img_path).convert(\"RGB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to tensor and normalize\n",
    "img_tensor = (PILToTensor()(img) / 255.0 - 0.5) * 2\n",
    "img_tensor = img_tensor.unsqueeze(0).cuda()  # [1, C, H, W]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Ludenbold\\Desktop\\Master V\\Image&Video Synthesis Prak\\dift-practical-image-synthesis\\src\\models\\dift_sd.py:99: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "c:\\Users\\Ludenbold\\Desktop\\Master V\\Image&Video Synthesis Prak\\dift-practical-image-synthesis\\src\\models\\dift_sd.py:89: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.no_grad(), torch.cuda.amp.autocast():\n",
      "c:\\Users\\Ludenbold\\Desktop\\Master V\\Image&Video Synthesis Prak\\dift-practical-image-synthesis\\src\\models\\dift_sd.py:112: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "the feature number of src and tgt must be equal to d_model",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m prompt \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ma photo of a cat\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m#features = featurizer.forward(img_tensor, prompt=prompt, t=261, up_ft_index=1)\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m features \u001b[38;5;241m=\u001b[39m \u001b[43mfeaturizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg_tensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m261\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Ludenbold\\anaconda3\\envs\\PrakDiFT\\lib\\site-packages\\torch\\utils\\_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[0;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    115\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[1;32m--> 116\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Ludenbold\\Desktop\\Master V\\Image&Video Synthesis Prak\\dift-practical-image-synthesis\\src\\models\\dift_sd.py:113\u001b[0m, in \u001b[0;36mSDFeaturizer.forward\u001b[1;34m(self, img_tensor, prompt, t)\u001b[0m\n\u001b[0;32m    111\u001b[0m \u001b[38;5;66;03m# Process the noisy latents through MM-DiT\u001b[39;00m\n\u001b[0;32m    112\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mamp\u001b[38;5;241m.\u001b[39mautocast():\n\u001b[1;32m--> 113\u001b[0m     features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmm_dit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnoisy_latents\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt_embeds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    115\u001b[0m \u001b[38;5;66;03m# Clear unused memory\u001b[39;00m\n\u001b[0;32m    116\u001b[0m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mempty_cache()\n",
      "File \u001b[1;32mc:\\Users\\Ludenbold\\anaconda3\\envs\\PrakDiFT\\lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Ludenbold\\anaconda3\\envs\\PrakDiFT\\lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\Ludenbold\\anaconda3\\envs\\PrakDiFT\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:268\u001b[0m, in \u001b[0;36mTransformer.forward\u001b[1;34m(self, src, tgt, src_mask, tgt_mask, memory_mask, src_key_padding_mask, tgt_key_padding_mask, memory_key_padding_mask, src_is_causal, tgt_is_causal, memory_is_causal)\u001b[0m\n\u001b[0;32m    265\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthe batch number of src and tgt must be equal\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    267\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m src\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39md_model \u001b[38;5;129;01mor\u001b[39;00m tgt\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39md_model:\n\u001b[1;32m--> 268\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m    269\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthe feature number of src and tgt must be equal to d_model\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    270\u001b[0m     )\n\u001b[0;32m    272\u001b[0m memory \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoder(\n\u001b[0;32m    273\u001b[0m     src,\n\u001b[0;32m    274\u001b[0m     mask\u001b[38;5;241m=\u001b[39msrc_mask,\n\u001b[0;32m    275\u001b[0m     src_key_padding_mask\u001b[38;5;241m=\u001b[39msrc_key_padding_mask,\n\u001b[0;32m    276\u001b[0m     is_causal\u001b[38;5;241m=\u001b[39msrc_is_causal,\n\u001b[0;32m    277\u001b[0m )\n\u001b[0;32m    278\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecoder(\n\u001b[0;32m    279\u001b[0m     tgt,\n\u001b[0;32m    280\u001b[0m     memory,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    286\u001b[0m     memory_is_causal\u001b[38;5;241m=\u001b[39mmemory_is_causal,\n\u001b[0;32m    287\u001b[0m )\n",
      "\u001b[1;31mRuntimeError\u001b[0m: the feature number of src and tgt must be equal to d_model"
     ]
    }
   ],
   "source": [
    "# Extract Features from MM-DiT Blocks\n",
    "prompt = \"a photo of a cat\"\n",
    "#features = featurizer.forward(img_tensor, prompt=prompt, t=261, up_ft_index=1)\n",
    "features = featurizer.forward(img_tensor, prompt=prompt, t=261)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display feature shape to confirm success\n",
    "print(\"Extracted feature shape:\", features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize or Process Extracted Features\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if features.dim() == 4:\n",
    "    feature_map = features[0, 0].cpu().numpy()  # Extract the first channel\n",
    "    plt.imshow(feature_map, cmap=\"viridis\")\n",
    "    plt.colorbar()\n",
    "    plt.title(\"Feature Map Visualization\")\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"Features are not spatial maps; check dimensions.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PrakDiFT",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
