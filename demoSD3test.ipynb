{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\ludenbold\\anaconda3\\envs\\prakdift\\lib\\site-packages (2.5.1+cu124)\n",
      "Requirement already satisfied: diffusers in c:\\users\\ludenbold\\anaconda3\\envs\\prakdift\\lib\\site-packages (0.13.0)\n",
      "Requirement already satisfied: transformers in c:\\users\\ludenbold\\anaconda3\\envs\\prakdift\\lib\\site-packages (4.46.2)\n",
      "Requirement already satisfied: safetensors in c:\\users\\ludenbold\\anaconda3\\envs\\prakdift\\lib\\site-packages (0.4.5)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\ludenbold\\anaconda3\\envs\\prakdift\\lib\\site-packages (3.9.2)\n",
      "Requirement already satisfied: pillow in c:\\users\\ludenbold\\anaconda3\\envs\\prakdift\\lib\\site-packages (10.4.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\ludenbold\\anaconda3\\envs\\prakdift\\lib\\site-packages (from torch) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\ludenbold\\anaconda3\\envs\\prakdift\\lib\\site-packages (from torch) (4.11.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\ludenbold\\anaconda3\\envs\\prakdift\\lib\\site-packages (from torch) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\ludenbold\\anaconda3\\envs\\prakdift\\lib\\site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\ludenbold\\anaconda3\\envs\\prakdift\\lib\\site-packages (from torch) (2024.10.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\ludenbold\\anaconda3\\envs\\prakdift\\lib\\site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\ludenbold\\anaconda3\\envs\\prakdift\\lib\\site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: importlib-metadata in c:\\users\\ludenbold\\anaconda3\\envs\\prakdift\\lib\\site-packages (from diffusers) (8.5.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.10.0 in c:\\users\\ludenbold\\anaconda3\\envs\\prakdift\\lib\\site-packages (from diffusers) (0.25.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\ludenbold\\anaconda3\\envs\\prakdift\\lib\\site-packages (from diffusers) (1.26.4)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\ludenbold\\anaconda3\\envs\\prakdift\\lib\\site-packages (from diffusers) (2024.11.6)\n",
      "Requirement already satisfied: requests in c:\\users\\ludenbold\\anaconda3\\envs\\prakdift\\lib\\site-packages (from diffusers) (2.32.3)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\ludenbold\\anaconda3\\envs\\prakdift\\lib\\site-packages (from transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\ludenbold\\anaconda3\\envs\\prakdift\\lib\\site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in c:\\users\\ludenbold\\anaconda3\\envs\\prakdift\\lib\\site-packages (from transformers) (0.20.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\ludenbold\\anaconda3\\envs\\prakdift\\lib\\site-packages (from transformers) (4.67.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\ludenbold\\anaconda3\\envs\\prakdift\\lib\\site-packages (from matplotlib) (1.3.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\ludenbold\\anaconda3\\envs\\prakdift\\lib\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\ludenbold\\anaconda3\\envs\\prakdift\\lib\\site-packages (from matplotlib) (4.54.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\ludenbold\\anaconda3\\envs\\prakdift\\lib\\site-packages (from matplotlib) (1.4.7)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\ludenbold\\anaconda3\\envs\\prakdift\\lib\\site-packages (from matplotlib) (3.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\ludenbold\\anaconda3\\envs\\prakdift\\lib\\site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\ludenbold\\anaconda3\\envs\\prakdift\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\ludenbold\\anaconda3\\envs\\prakdift\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: zipp>=3.20 in c:\\users\\ludenbold\\anaconda3\\envs\\prakdift\\lib\\site-packages (from importlib-metadata->diffusers) (3.20.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\ludenbold\\anaconda3\\envs\\prakdift\\lib\\site-packages (from jinja2->torch) (3.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\ludenbold\\anaconda3\\envs\\prakdift\\lib\\site-packages (from requests->diffusers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\ludenbold\\anaconda3\\envs\\prakdift\\lib\\site-packages (from requests->diffusers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\ludenbold\\anaconda3\\envs\\prakdift\\lib\\site-packages (from requests->diffusers) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\ludenbold\\anaconda3\\envs\\prakdift\\lib\\site-packages (from requests->diffusers) (2024.8.30)\n",
      "Requirement already satisfied: diffusers==0.13.0 in c:\\users\\ludenbold\\anaconda3\\envs\\prakdift\\lib\\site-packages (0.13.0)\n",
      "Requirement already satisfied: importlib-metadata in c:\\users\\ludenbold\\anaconda3\\envs\\prakdift\\lib\\site-packages (from diffusers==0.13.0) (8.5.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\ludenbold\\anaconda3\\envs\\prakdift\\lib\\site-packages (from diffusers==0.13.0) (3.16.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.10.0 in c:\\users\\ludenbold\\anaconda3\\envs\\prakdift\\lib\\site-packages (from diffusers==0.13.0) (0.25.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\ludenbold\\anaconda3\\envs\\prakdift\\lib\\site-packages (from diffusers==0.13.0) (1.26.4)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\ludenbold\\anaconda3\\envs\\prakdift\\lib\\site-packages (from diffusers==0.13.0) (2024.11.6)\n",
      "Requirement already satisfied: requests in c:\\users\\ludenbold\\anaconda3\\envs\\prakdift\\lib\\site-packages (from diffusers==0.13.0) (2.32.3)\n",
      "Requirement already satisfied: Pillow in c:\\users\\ludenbold\\anaconda3\\envs\\prakdift\\lib\\site-packages (from diffusers==0.13.0) (10.4.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\ludenbold\\anaconda3\\envs\\prakdift\\lib\\site-packages (from huggingface-hub>=0.10.0->diffusers==0.13.0) (2024.10.0)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\users\\ludenbold\\anaconda3\\envs\\prakdift\\lib\\site-packages (from huggingface-hub>=0.10.0->diffusers==0.13.0) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\ludenbold\\anaconda3\\envs\\prakdift\\lib\\site-packages (from huggingface-hub>=0.10.0->diffusers==0.13.0) (6.0.2)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in c:\\users\\ludenbold\\anaconda3\\envs\\prakdift\\lib\\site-packages (from huggingface-hub>=0.10.0->diffusers==0.13.0) (4.67.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\ludenbold\\anaconda3\\envs\\prakdift\\lib\\site-packages (from huggingface-hub>=0.10.0->diffusers==0.13.0) (4.11.0)\n",
      "Requirement already satisfied: zipp>=3.20 in c:\\users\\ludenbold\\anaconda3\\envs\\prakdift\\lib\\site-packages (from importlib-metadata->diffusers==0.13.0) (3.20.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\ludenbold\\anaconda3\\envs\\prakdift\\lib\\site-packages (from requests->diffusers==0.13.0) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\ludenbold\\anaconda3\\envs\\prakdift\\lib\\site-packages (from requests->diffusers==0.13.0) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\ludenbold\\anaconda3\\envs\\prakdift\\lib\\site-packages (from requests->diffusers==0.13.0) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\ludenbold\\anaconda3\\envs\\prakdift\\lib\\site-packages (from requests->diffusers==0.13.0) (2024.8.30)\n",
      "Requirement already satisfied: colorama in c:\\users\\ludenbold\\anaconda3\\envs\\prakdift\\lib\\site-packages (from tqdm>=4.42.1->huggingface-hub>=0.10.0->diffusers==0.13.0) (0.4.6)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Ludenbold\\anaconda3\\envs\\PrakDiFT\\lib\\site-packages\\torchvision\\io\\image.py:13: UserWarning: Failed to load image Python extension: [WinError 127] Die angegebene Prozedur wurde nicht gefunden\n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n"
     ]
    }
   ],
   "source": [
    "%matplotlib widget\n",
    "# Demo for DIFT with Stable Diffusion 3\n",
    "\n",
    "# Ensure required libraries are installed\n",
    "!pip install torch diffusers transformers safetensors matplotlib pillow\n",
    "!pip install diffusers==0.13.0\n",
    "\n",
    "# Import Libraries and Initialize Featurizer\n",
    "from src.models.dift_sd import SDFeaturizer\n",
    "from torchvision.transforms import PILToTensor\n",
    "from PIL import Image\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29cc519f3ca14d388f0e64780fe187a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Login to Hugging Face to access the model\n",
    "from huggingface_hub import login\n",
    "login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.path.exists(\"./sd3_medium.safetensors\"))  # Should return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Ludenbold\\anaconda3\\envs\\PrakDiFT\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 64.00 MiB. GPU 0 has a total capacity of 12.00 GiB of which 0 bytes is free. Of the allocated memory 22.51 GiB is allocated by PyTorch, and 128.00 KiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 7\u001b[0m\n\u001b[0;32m      5\u001b[0m current_dir \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mdirname(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mabspath(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./dift_sd.py\u001b[39m\u001b[38;5;124m\"\u001b[39m))  \u001b[38;5;66;03m# Get the current directory of dift_sd.py\u001b[39;00m\n\u001b[0;32m      6\u001b[0m model_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(current_dir, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msd3_medium.safetensors\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 7\u001b[0m featurizer \u001b[38;5;241m=\u001b[39m \u001b[43mSDFeaturizer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_path\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Ludenbold\\Desktop\\Master V\\Image&Video Synthesis Prak\\dift-practical-image-synthesis\\src\\models\\dift_sd.py:210\u001b[0m, in \u001b[0;36mSDFeaturizer.__init__\u001b[1;34m(self, model_path, null_prompt)\u001b[0m\n\u001b[0;32m    207\u001b[0m state_dict \u001b[38;5;241m=\u001b[39m load_file(model_path)\n\u001b[0;32m    209\u001b[0m \u001b[38;5;66;03m# Initialize MM-DiT (U-Net equivalent)\u001b[39;00m\n\u001b[1;32m--> 210\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmm_dit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_initialize_mm_dit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate_dict\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    212\u001b[0m \u001b[38;5;66;03m# Load VAE for latent encoding\u001b[39;00m\n\u001b[0;32m    213\u001b[0m \u001b[38;5;66;03m# Replace the VAE loading in the initializer\u001b[39;00m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvae \u001b[38;5;241m=\u001b[39m AutoencoderKL\u001b[38;5;241m.\u001b[39mfrom_pretrained(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstabilityai/stable-diffusion-2-1\u001b[39m\u001b[38;5;124m\"\u001b[39m, subfolder\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvae\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Ludenbold\\Desktop\\Master V\\Image&Video Synthesis Prak\\dift-practical-image-synthesis\\src\\models\\dift_sd.py:238\u001b[0m, in \u001b[0;36mSDFeaturizer._initialize_mm_dit\u001b[1;34m(self, state_dict)\u001b[0m\n\u001b[0;32m    228\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    229\u001b[0m \u001b[38;5;124;03mInitialize the MM-DiT (transformer-based U-Net) from the provided state_dict.\u001b[39;00m\n\u001b[0;32m    230\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    231\u001b[0m \u001b[38;5;66;03m# Example configuration for MM-DiT (customize as per the architecture)\u001b[39;00m\n\u001b[0;32m    232\u001b[0m mm_dit \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTransformer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    233\u001b[0m \u001b[43m    \u001b[49m\u001b[43md_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m4096\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Adjust dimensions\u001b[39;49;00m\n\u001b[0;32m    234\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnhead\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m16\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m      \u001b[49m\u001b[38;5;66;43;03m# Number of attention heads\u001b[39;49;00m\n\u001b[0;32m    235\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_encoder_layers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m24\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    236\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_decoder_layers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m24\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    237\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdim_feedforward\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m8192\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m--> 238\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcuda\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    239\u001b[0m mm_dit\u001b[38;5;241m.\u001b[39mload_state_dict(state_dict, strict\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m    240\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m mm_dit\n",
      "File \u001b[1;32mc:\\Users\\Ludenbold\\anaconda3\\envs\\PrakDiFT\\lib\\site-packages\\torch\\nn\\modules\\module.py:1340\u001b[0m, in \u001b[0;36mModule.to\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1337\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1338\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[1;32m-> 1340\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Ludenbold\\anaconda3\\envs\\PrakDiFT\\lib\\site-packages\\torch\\nn\\modules\\module.py:900\u001b[0m, in \u001b[0;36mModule._apply\u001b[1;34m(self, fn, recurse)\u001b[0m\n\u001b[0;32m    898\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[0;32m    899\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[1;32m--> 900\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    902\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[0;32m    903\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[0;32m    904\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[0;32m    905\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    910\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[0;32m    911\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Ludenbold\\anaconda3\\envs\\PrakDiFT\\lib\\site-packages\\torch\\nn\\modules\\module.py:900\u001b[0m, in \u001b[0;36mModule._apply\u001b[1;34m(self, fn, recurse)\u001b[0m\n\u001b[0;32m    898\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[0;32m    899\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[1;32m--> 900\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    902\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[0;32m    903\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[0;32m    904\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[0;32m    905\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    910\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[0;32m    911\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "    \u001b[1;31m[... skipping similar frames: Module._apply at line 900 (2 times)]\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\Ludenbold\\anaconda3\\envs\\PrakDiFT\\lib\\site-packages\\torch\\nn\\modules\\module.py:900\u001b[0m, in \u001b[0;36mModule._apply\u001b[1;34m(self, fn, recurse)\u001b[0m\n\u001b[0;32m    898\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[0;32m    899\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[1;32m--> 900\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    902\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[0;32m    903\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[0;32m    904\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[0;32m    905\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    910\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[0;32m    911\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Ludenbold\\anaconda3\\envs\\PrakDiFT\\lib\\site-packages\\torch\\nn\\modules\\module.py:927\u001b[0m, in \u001b[0;36mModule._apply\u001b[1;34m(self, fn, recurse)\u001b[0m\n\u001b[0;32m    923\u001b[0m \u001b[38;5;66;03m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[0;32m    924\u001b[0m \u001b[38;5;66;03m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[0;32m    925\u001b[0m \u001b[38;5;66;03m# `with torch.no_grad():`\u001b[39;00m\n\u001b[0;32m    926\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m--> 927\u001b[0m     param_applied \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparam\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    928\u001b[0m p_should_use_set_data \u001b[38;5;241m=\u001b[39m compute_should_use_set_data(param, param_applied)\n\u001b[0;32m    930\u001b[0m \u001b[38;5;66;03m# subclasses may have multiple child tensors so we need to use swap_tensors\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Ludenbold\\anaconda3\\envs\\PrakDiFT\\lib\\site-packages\\torch\\nn\\modules\\module.py:1326\u001b[0m, in \u001b[0;36mModule.to.<locals>.convert\u001b[1;34m(t)\u001b[0m\n\u001b[0;32m   1319\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m convert_to_format \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m t\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m5\u001b[39m):\n\u001b[0;32m   1320\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(\n\u001b[0;32m   1321\u001b[0m             device,\n\u001b[0;32m   1322\u001b[0m             dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1323\u001b[0m             non_blocking,\n\u001b[0;32m   1324\u001b[0m             memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format,\n\u001b[0;32m   1325\u001b[0m         )\n\u001b[1;32m-> 1326\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1327\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1328\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_floating_point\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_complex\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1329\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1330\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1331\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m   1332\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(e) \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot copy out of meta tensor; no data!\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "\u001b[1;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 64.00 MiB. GPU 0 has a total capacity of 12.00 GiB of which 0 bytes is free. Of the allocated memory 22.51 GiB is allocated by PyTorch, and 128.00 KiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "source": [
    "# Initialize the SDFeaturizer for Stable Diffusion 3\n",
    "# Assuming 'sd3_medium.safetensors' is in the same directory as 'demoSD3test.ipynb'\n",
    "import os\n",
    "\n",
    "current_dir = os.path.dirname(os.path.abspath(\"./dift_sd.py\"))  # Get the current directory of dift_sd.py\n",
    "model_path = os.path.join(current_dir, \"sd3_medium.safetensors\")\n",
    "featurizer = SDFeaturizer(model_path=model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and Process a Sample Image\n",
    "img_path = \"./assets/cat.png\"  # Replace with your image path\n",
    "img = Image.open(img_path).convert(\"RGB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to tensor and normalize\n",
    "img_tensor = (PILToTensor()(img) / 255.0 - 0.5) * 2\n",
    "img_tensor = img_tensor.unsqueeze(0).cuda()  # [1, C, H, W]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract Features from MM-DiT Blocks\n",
    "prompt = \"a photo of a cat\"\n",
    "features = featurizer.forward(img_tensor, prompt=prompt, t=261, up_ft_index=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display feature shape to confirm success\n",
    "print(\"Extracted feature shape:\", features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize or Process Extracted Features\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if features.dim() == 4:\n",
    "    feature_map = features[0, 0].cpu().numpy()  # Extract the first channel\n",
    "    plt.imshow(feature_map, cmap=\"viridis\")\n",
    "    plt.colorbar()\n",
    "    plt.title(\"Feature Map Visualization\")\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"Features are not spatial maps; check dimensions.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PrakDiFT",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
